#!/usr/bin/env python3
"""
Import des donn√©es DATAtourisme (CSV) vers PostgreSQL
Solution nationale compl√®te avec g√©olocalisation
"""

import requests
import csv
from io import StringIO
import psycopg2
from psycopg2.extras import execute_batch
from datetime import datetime, timedelta
from math import radians, sin, cos, sqrt, atan2
import json


# ============================================================================
# CONFIGURATION
# ============================================================================

import os
from urllib.parse import urlparse

# URL de ta base PostgreSQL sur Render
DATABASE_URL = os.environ.get('DATABASE_URL') or "postgresql://data_tourisme_user:B2zwMxZNbbU3LHKFFQrtIiY1VABoEuEo@dpg-d4hngejuibrs73do1jf0-a.frankfurt-postgres.render.com/data_tourisme"

if DATABASE_URL:
    # Parser l'URL de Render
    url = urlparse(DATABASE_URL)
    DB_CONFIG = {
        'host': url.hostname,
        'port': url.port or 5432,
        'database': url.path[1:],  # Enlever le / initial
        'user': url.username,
        'password': url.password,
        'sslmode': 'require'  # Important pour Render
    }
    print(f"‚úÖ Connexion √† Render: {url.hostname}")
else:
    # Configuration locale (ne sera pas utilis√©e)
    DB_CONFIG = {
        'host': 'localhost',
        'port': 5432,
        'database': 'datatourisme',
        'user': 'postgres',
        'password': 'votre_mot_de_passe',
        'sslmode': 'prefer'
    }
    print(f"‚ö†Ô∏è  Connexion locale: {DB_CONFIG['host']}")

# DATAtourisme
DATASET_ID = "5b598be088ee387c0c353714"
DATA_GOUV_API = f"https://www.data.gouv.fr/api/1/datasets/{DATASET_ID}/"


# ============================================================================
# FONCTIONS BASE DE DONN√âES
# ============================================================================

def creer_base_donnees():
    """Cr√©e la structure de la base de donn√©es"""
    
    print("üî® Cr√©ation de la base de donn√©es...")
    
    conn = psycopg2.connect(**DB_CONFIG)
    conn.autocommit = True  # Important pour CREATE EXTENSION
    cur = conn.cursor()
    
    try:
        # Activer l'extension PostGIS pour la g√©olocalisation
        print("   üìç Activation de PostGIS...")
        cur.execute("CREATE EXTENSION IF NOT EXISTS postgis;")
        print("   ‚úÖ PostGIS activ√©")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  PostGIS: {e}")
        print("   üí° Si erreur de permission, PostGIS est peut-√™tre d√©j√† activ√©")
    
    conn.autocommit = False  # Revenir au mode transaction
    
    # Table des √©v√©nements
    cur.execute("""
        DROP TABLE IF EXISTS evenements CASCADE;
        
        CREATE TABLE evenements (
            id SERIAL PRIMARY KEY,
            uri TEXT UNIQUE,
            nom TEXT NOT NULL,
            categories TEXT[],
            latitude DOUBLE PRECISION,
            longitude DOUBLE PRECISION,
            geom GEOMETRY(Point, 4326),  -- PostGIS
            adresse TEXT,
            code_postal TEXT,
            commune TEXT,
            periodes TEXT,
            date_debut DATE,
            date_fin DATE,
            contacts TEXT,
            classements TEXT,
            description TEXT,
            mesures_covid TEXT,
            createur TEXT,
            sit_diffuseur TEXT,
            date_maj TIMESTAMP,
            created_at TIMESTAMP DEFAULT NOW()
        );
        
        -- Index g√©ospatiaux
        CREATE INDEX idx_evenements_geom ON evenements USING GIST(geom);
        CREATE INDEX idx_evenements_dates ON evenements(date_debut, date_fin);
        CREATE INDEX idx_evenements_commune ON evenements(commune);
        CREATE INDEX idx_evenements_code_postal ON evenements(code_postal);
        CREATE INDEX idx_evenements_categories ON evenements USING GIN(categories);
    """)
    
    conn.commit()
    cur.close()
    conn.close()
    
    print("‚úÖ Base de donn√©es cr√©√©e avec succ√®s")


def trouver_url_csv_evenements():
    """Trouve l'URL du fichier CSV √©v√©nements via l'API data.gouv.fr"""
    
    print("üîç Recherche de l'URL du fichier CSV...")
    
    try:
        response = requests.get(DATA_GOUV_API, timeout=30)
        response.raise_for_status()
        
        dataset = response.json()
        resources = dataset.get('resources', [])
        
        for resource in resources:
            title = resource.get('title', '').lower()
            format_type = resource.get('format', '').lower()
            
            # Chercher le fichier FMA (√©v√©nements)
            if format_type == 'csv' and ('fma' in title or '√©v√©nement' in title or 'manifestation' in title):
                url = resource.get('url')
                print(f"‚úÖ Fichier trouv√©: {resource.get('title')}")
                print(f"   URL: {url}\n")
                return url
        
        print("‚ùå Aucun fichier CSV d'√©v√©nements trouv√©")
        return None
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return None


def telecharger_et_importer_csv(url):
    """T√©l√©charge le CSV et l'importe dans PostgreSQL"""
    
    if not url:
        return 0
    
    print(f"üì• T√©l√©chargement du fichier CSV...")
    print(f"   Cela peut prendre 1-2 minutes...\n")
    
    try:
        response = requests.get(url, timeout=300)  # 5 minutes timeout
        response.raise_for_status()
        
        size_mb = len(response.content) / (1024 * 1024)
        print(f"‚úÖ T√©l√©charg√©: {size_mb:.2f} MB")
        
        print("üìä Lecture du CSV...")
        content = response.content.decode('utf-8', errors='ignore')
        csv_file = StringIO(content)
        reader = csv.DictReader(csv_file)
        
        evenements = list(reader)
        print(f"‚úÖ {len(evenements)} √©v√©nements lus\n")
        
        # Import dans PostgreSQL
        print("üíæ Import dans PostgreSQL...")
        count = importer_evenements_postgres(evenements)
        
        return count
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 0


def parser_periodes(periodes_str):
    """Parse les p√©riodes et retourne la premi√®re date de d√©but et fin"""
    
    if not periodes_str:
        return None, None
    
    try:
        # Format: 2024-06-15<->2024-06-20|2024-07-01<->2024-07-10
        periodes = periodes_str.split('|')
        if periodes:
            premiere = periodes[0].split('<->')
            if len(premiere) == 2:
                debut = datetime.strptime(premiere[0].strip(), '%Y-%m-%d').date()
                fin = datetime.strptime(premiere[1].strip(), '%Y-%m-%d').date()
                return debut, fin
    except:
        pass
    
    return None, None


def parser_categories(categories_str):
    """Parse les cat√©gories en tableau"""
    
    if not categories_str:
        return []
    
    # Format: https://url1|https://url2
    categories = categories_str.split('|')
    
    # Extraire seulement le dernier segment de l'URL
    result = []
    for cat in categories:
        if '/' in cat:
            result.append(cat.split('/')[-1])
        else:
            result.append(cat)
    
    return result


def parser_code_postal_commune(cp_commune_str):
    """Parse le format code_postal#commune"""
    
    if not cp_commune_str:
        return None, None
    
    try:
        parts = cp_commune_str.split('#')
        if len(parts) == 2:
            return parts[0].strip(), parts[1].strip()
    except:
        pass
    
    return None, None


def importer_evenements_postgres(evenements):
    """Importe les √©v√©nements dans PostgreSQL par batch"""
    
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    
    # Pr√©parer les donn√©es
    data_to_insert = []
    skipped = 0
    
    for event in evenements:
        try:
            # Coordonn√©es GPS
            lat = event.get('Latitude')
            lon = event.get('Longitude')
            
            if not lat or not lon:
                skipped += 1
                continue
            
            lat = float(lat)
            lon = float(lon)
            
            # Parser les p√©riodes
            periodes = event.get('Periodes_regroupees', '')
            date_debut, date_fin = parser_periodes(periodes)
            
            # Parser cat√©gories
            categories = parser_categories(event.get('Categories_de_POI', ''))
            
            # Parser code postal et commune
            cp, commune = parser_code_postal_commune(event.get('Code_postal_et_commune', ''))
            
            # Date de mise √† jour
            date_maj_str = event.get('Date_de_mise_a_jour', '')
            try:
                date_maj = datetime.fromisoformat(date_maj_str.replace('Z', '+00:00'))
            except:
                date_maj = None
            
            data_to_insert.append((
                event.get('URI_ID_du_POI', ''),
                event.get('Nom_du_POI', 'Sans nom'),
                categories,
                lat,
                lon,
                f'POINT({lon} {lat})',  # PostGIS
                event.get('Adresse_postale', ''),
                cp,
                commune,
                periodes,
                date_debut,
                date_fin,
                event.get('Contacts_du_POI', ''),
                event.get('Classements_du_POI', ''),
                event.get('Description', ''),
                event.get('Covid19_mesures_specifiques', ''),
                event.get('Createur_de_la_donnee', ''),
                event.get('SIT_diffuseur', ''),
                date_maj
            ))
            
        except Exception as e:
            skipped += 1
            continue
    
    print(f"   Pr√©paration: {len(data_to_insert)} √©v√©nements √† importer")
    print(f"   Ignor√©s: {skipped} (sans coordonn√©es)\n")
    
    # Import par batch (plus rapide)
    query = """
        INSERT INTO evenements (
            uri, nom, categories, latitude, longitude, geom,
            adresse, code_postal, commune, periodes,
            date_debut, date_fin, contacts, classements,
            description, mesures_covid, createur, sit_diffuseur, date_maj
        ) VALUES (
            %s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326),
            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
        )
        ON CONFLICT (uri) DO UPDATE SET
            nom = EXCLUDED.nom,
            categories = EXCLUDED.categories,
            latitude = EXCLUDED.latitude,
            longitude = EXCLUDED.longitude,
            geom = EXCLUDED.geom,
            adresse = EXCLUDED.adresse,
            code_postal = EXCLUDED.code_postal,
            commune = EXCLUDED.commune,
            periodes = EXCLUDED.periodes,
            date_debut = EXCLUDED.date_debut,
            date_fin = EXCLUDED.date_fin,
            contacts = EXCLUDED.contacts,
            classements = EXCLUDED.classements,
            description = EXCLUDED.description,
            date_maj = EXCLUDED.date_maj
    """
    
    execute_batch(cur, query, data_to_insert, page_size=1000)
    
    conn.commit()
    cur.close()
    conn.close()
    
    print(f"‚úÖ {len(data_to_insert)} √©v√©nements import√©s dans PostgreSQL")
    
    return len(data_to_insert)


def afficher_statistiques():
    """Affiche les statistiques de la base"""
    
    print("\n" + "="*70)
    print("üìä STATISTIQUES DE LA BASE")
    print("="*70 + "\n")
    
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    
    # Total √©v√©nements
    cur.execute("SELECT COUNT(*) FROM evenements")
    total = cur.fetchone()[0]
    print(f"üìç Total √©v√©nements: {total:,}")
    
    # Par r√©gion (top 10)
    cur.execute("""
        SELECT commune, COUNT(*) as count
        FROM evenements
        WHERE commune IS NOT NULL
        GROUP BY commune
        ORDER BY count DESC
        LIMIT 10
    """)
    print("\nüèôÔ∏è  Top 10 communes:")
    for commune, count in cur.fetchall():
        print(f"   {commune}: {count:,}")
    
    # √âv√©nements √† venir
    cur.execute("""
        SELECT COUNT(*)
        FROM evenements
        WHERE date_debut >= CURRENT_DATE
    """)
    futurs = cur.fetchone()[0]
    print(f"\nüìÖ √âv√©nements √† venir: {futurs:,}")
    
    # Taille de la base
    cur.execute("""
        SELECT pg_size_pretty(pg_total_relation_size('evenements'))
    """)
    size = cur.fetchone()[0]
    print(f"\nüíæ Taille de la table: {size}")
    
    cur.close()
    conn.close()


# ============================================================================
# FONCTION DE RECHERCHE
# ============================================================================

def rechercher_evenements(latitude, longitude, rayon_km, jours_avant=30):
    """Recherche des √©v√©nements dans PostgreSQL"""
    
    print(f"\nüîç Recherche d'√©v√©nements...")
    print(f"   Centre: ({latitude}, {longitude})")
    print(f"   Rayon: {rayon_km} km")
    print(f"   P√©riode: {jours_avant} jours\n")
    
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    
    date_limite = datetime.now().date() + timedelta(days=jours_avant)
    
    # Requ√™te avec PostGIS
    query = """
        SELECT 
            nom,
            commune,
            date_debut,
            ST_Distance(
                geom::geography,
                ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography
            ) / 1000 as distance_km
        FROM evenements
        WHERE ST_DWithin(
            geom::geography,
            ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography,
            %s  -- rayon en m√®tres
        )
        AND (date_debut IS NULL OR date_debut <= %s)
        AND (date_fin IS NULL OR date_fin >= CURRENT_DATE)
        ORDER BY distance_km, date_debut
        LIMIT 50
    """
    
    cur.execute(query, (
        longitude, latitude,  # Pour le calcul de distance
        longitude, latitude,  # Pour le filtre g√©ographique
        rayon_km * 1000,      # Rayon en m√®tres
        date_limite
    ))
    
    results = cur.fetchall()
    
    print(f"‚úÖ {len(results)} √©v√©nements trouv√©s\n")
    
    for i, (nom, commune, date, distance) in enumerate(results[:10], 1):
        date_str = date.strftime('%d/%m/%Y') if date else 'Date non pr√©cis√©e'
        print(f"{i}. {nom}")
        print(f"   üìç {commune} ({distance:.1f} km)")
        print(f"   üìÖ {date_str}\n")
    
    cur.close()
    conn.close()
    
    return results


# ============================================================================
# PROGRAMME PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    
    print("="*70)
    print("üéØ DATATOURISME ‚Üí POSTGRESQL")
    print("="*70)
    print()
    
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'search':
        # Mode recherche
        rechercher_evenements(43.6047, 1.4442, 30, 30)
    
    else:
        # Mode import
        print("1Ô∏è‚É£  Cr√©ation de la structure...")
        creer_base_donnees()
        print()
        
        print("2Ô∏è‚É£  Recherche du fichier CSV...")
        url = trouver_url_csv_evenements()
        print()
        
        if url:
            print("3Ô∏è‚É£  T√©l√©chargement et import...")
            count = telecharger_et_importer_csv(url)
            print()
            
            if count > 0:
                print("4Ô∏è‚É£  Statistiques...")
                afficher_statistiques()
                print()
                
                print("="*70)
                print("‚úÖ IMPORT TERMIN√â !")
                print("="*70)
                print()
                print("üí° Pour rechercher des √©v√©nements:")
                print("   python import_datatourisme.py search")
                print()
        else:
            print("‚ùå Impossible de trouver le fichier CSV")
